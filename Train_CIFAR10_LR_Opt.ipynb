{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-pShTXdFmEq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as dset\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 256"
      ],
      "metadata": {
        "id": "8P16MYkI-v2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print('GPU State:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYc_EqtPF48W",
        "outputId": "c51baf7c-a24e-437a-e48e-3da11fcdd311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU State: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,)),]\n",
        ")"
      ],
      "metadata": {
        "id": "I0fZjyaoF5lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Data\n",
        "trainSet = datasets.CIFAR10(root='CIFAR10', download=True, train=True, transform=transform)\n",
        "testSet = datasets.CIFAR10(root='CIFAR10', download=True, train=False, transform=transform)\n",
        "trainLoader = dset.DataLoader(trainSet, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testLoader = dset.DataLoader(testSet, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "QEtpI6yAF5jB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c47b61f-3030-4245-ad28-bc934c61c96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to CIFAR10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 28534399.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting CIFAR10/cifar-10-python.tar.gz to CIFAR10\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (data, target) in enumerate(trainLoader):\n",
        "    batch_size = data.size()\n",
        "    print(\"Batch size:\", batch_size[0])\n",
        "    print(\"Color Channels:\", batch_size[1])\n",
        "    print(\"Image size:\", batch_size[2],'x', batch_size[3])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2IRUiWkGDTy",
        "outputId": "d053787c-83a8-4537-92bb-c0cc5d4a01a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 256\n",
            "Color Channels: 3\n",
            "Image size: 32 x 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()#120, 3, 32, 32\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=4),\n",
        "            nn.MaxPool2d(kernel_size=(4,4)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=1568, out_features=128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=128, out_features=64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=64, out_features=10),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "\n",
        "net = Net().to(device)\n",
        "print(net)"
      ],
      "metadata": {
        "id": "wzuHKNhPGEUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d2543a-a71e-4d2c-bbf1-330bb034e42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=(4, 4), stride=(4, 4), padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): Flatten(start_dim=1, end_dim=-1)\n",
            "    (3): Linear(in_features=1568, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (6): ReLU()\n",
            "    (7): Linear(in_features=64, out_features=10, bias=True)\n",
            "    (8): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "v7ErQFUeHLw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "from matplotlib import pyplot as plt\n",
        "def train():\n",
        "  loss4graph = []\n",
        "  for epoch in range(epochs):\n",
        "      running_loss = 0.0\n",
        "\n",
        "      for times, data in enumerate(trainLoader):\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          # Zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Foward + backward + optimize\n",
        "          outputs = net(inputs)\n",
        "\n",
        "          #break\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Print statistics\n",
        "          running_loss += loss.item()\n",
        "          if times % 10000 == 9999 or times+1 == len(trainLoader):\n",
        "              print(\"Epoch:\", epoch+1, \"  Loss:\", round(running_loss,2))\n",
        "              #print('[%d/%d, %d/%d] loss: %.3f' % (epoch+1, epochs, times+1, len(trainLoader), running_loss/2000))\n",
        "              loss4graph.append(running_loss)\n",
        "      scheduler.step()\n",
        "\n",
        "  print('Training Finished.')\n",
        "  plt.plot(loss4graph)"
      ],
      "metadata": {
        "id": "0yjyC6q2GGfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "def test():\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    #    for times, data in enumerate(trainLoader):\n",
        "\n",
        "      for data in testLoader:\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "          #inputs = inputs.view(inputs.shape[0], -1)\n",
        "\n",
        "          outputs = net(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  accuracies.append(100*correct / total)\n",
        "  print(100*correct / total)\n"
      ],
      "metadata": {
        "id": "xKkw1di9GHzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#static parameters\n",
        "accuracies = []\n",
        "epochs = 15\n",
        "learning_rates = [0.005, 0.01, 0.015, 0.02]\n",
        "\n",
        "# Adjusting Parameters\n",
        "for learning_rate in learning_rates:\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.7)\n",
        "  scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9, verbose = True)\n",
        "  train()\n",
        "  test()"
      ],
      "metadata": {
        "id": "MbLnp9C-CH0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_accuracy = max(accuracies)\n",
        "#max_lr = learning_rates[max_accuracy.index()]\n",
        "\n",
        "stop_layer_index = 4  # Index of the layer before nn.Softmax\n",
        "for idx, layer in enumerate(net.main):\n",
        "    if idx == stop_layer_index:\n",
        "        break\n",
        "    print(layer)\n",
        "print('\\nAccuracy: %d %%' % max_accuracy)\n",
        "#print('Best LR:', max_lr)"
      ],
      "metadata": {
        "id": "2lYmRLK6GIkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9272bf89-9d47-4149-cd58-3f1ce8747b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d(3, 32, kernel_size=(4, 4), stride=(1, 1))\n",
            "MaxPool2d(kernel_size=(4, 4), stride=(4, 4), padding=0, dilation=1, ceil_mode=False)\n",
            "Flatten(start_dim=1, end_dim=-1)\n",
            "Linear(in_features=1568, out_features=128, bias=True)\n",
            "\n",
            "Accuracy: 53 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Conv layer: 93%"
      ],
      "metadata": {
        "id": "LF0GM4LOHGDS"
      }
    }
  ]
}